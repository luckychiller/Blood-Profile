


PS F:\ML project\model\blood profile> python ./yolov7/train.py --weights ./yolov7/yolov7.pt --cfg ./yolov7/cfg/training/yolov7.yaml --data ./yolov7/data/coco.yaml --batch-size 4 --epochs 20 --img-size 640 640 --hyp
./yolov7/data/hyp.scratch.custom.yaml --name run --device cuda
2024-06-16 10:20:37.802041: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2024-06-16 10:20:39.268375: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
YOLOR  2024-5-30 torch 2.3.1+cu118 CUDA:cuda (NVIDIA GeForce MX250, 2047.875MB)

Namespace(weights='./yolov7/yolov7.pt', cfg='./yolov7/cfg/training/yolov7.yaml', data='./yolov7/data/coco.yaml', hyp='./yolov7/data/hyp.scratch.custom.yaml', epochs=200, batch_size=4, img_size=[640, 640], rect=False, resume=False, nosave=False, notest=False, noautoanchor=False, evolve=False, bucket='', cache_images=False, image_weights=False, device='cuda', multi_scale=False, single_cls=False, adam=False, sync_bn=False, local_rank=-1, workers=8, project='runs/train', entity=None, name='run', exist_ok=False, quad=False, linear_lr=False, label_smoothing=0.0, upload_dataset=False, bbox_interval=-1, save_period=-1, artifact_alias='latest', freeze=[0], v5_metric=False, world_size=1, global_rank=-1, save_dir='runs\\train\\run', total_batch_size=4)
tensorboard: Start with 'tensorboard --logdir runs/train', view at http://localhost:6006/
hyperparameters: lr0=0.01, lrf=0.1, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.3, cls_pw=1.0, obj=0.7, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.2, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, paste_in=0.0, loss_ota=1
config set opt = {'weights': './yolov7/yolov7.pt', 'cfg': './yolov7/cfg/training/yolov7.yaml', 'data': './yolov7/data/coco.yaml', 'hyp': {'lr0': 0.01, 'lrf': 0.1, 'momentum': 0.937, 'weight_decay': 0.0005, 'warmup_epochs': 3.0, 'warmup_momentum': 0.8, 'warmup_bias_lr': 0.1, 'box': 0.05, 'cls': 0.3, 'cls_pw': 1.0, 'obj': 0.7, 'obj_pw': 1.0, 'iou_t': 0.2, 'anchor_t': 4.0, 'fl_gamma': 0.0, 'hsv_h': 0.015, 'hsv_s': 0.7, 'hsv_v': 0.4, 'degrees': 0.0, 'translate': 0.2, 'scale': 0.5, 'shear': 0.0, 'perspective': 0.0, 'flipud': 0.0, 'fliplr': 0.5, 'mosaic': 1.0, 'mixup': 0.0, 'copy_paste': 0.0, 'paste_in': 0.0, 'loss_ota': 1}, 'epochs': 200, 'batch_size': 4, 'img_size': [640, 640], 'rect': False, 'resume': False, 'nosave': False, 'notest': False, 'noautoanchor': False, 'evolve': False, 'bucket': '', 'cache_images': False, 'image_weights': False, 'device': 'cuda', 'multi_scale': False, 'single_cls': False, 'adam': False, 'sync_bn': False, 'local_rank': -1, 'workers': 8, 'project': 'runs/train', 'entity': None, 'name': 'run', 'exist_ok': False, 'quad': False, 'linear_lr': False, 'label_smoothing': 0.0, 'upload_dataset': False, 'bbox_interval': -1, 'save_period': -1, 'artifact_alias': 'latest', 'freeze': [0], 'v5_metric': False, 'world_size': 1, 'global_rank': -1, 'save_dir': 'runs\\train\\run', 'total_batch_size': 4} - None
config set data_dict = {'train': './yolov7/dataset/train', 'val': './yolov7/dataset/test', 'nc': 3, 'names': ['Platelets', 'RBC', 'WBC']} - None

                   from   n     params    module                                  arguments
  backbone:
  0                  -1   1        928    models.common.Conv                      [3, 32, 3, 1]                 
  1                  -1   1      18560    models.common.Conv                      [32, 64, 3, 2]
  2                  -1   1      36992    models.common.Conv                      [64, 64, 3, 1]
  3                  -1   1      73984    models.common.Conv                      [64, 128, 3, 2]
  4                  -1   1       8320    models.common.Conv                      [128, 64, 1, 1]
  5                  -2   1       8320    models.common.Conv                      [128, 64, 1, 1]
  6                  -1   1      36992    models.common.Conv                      [64, 64, 3, 1]
  7                  -1   1      36992    models.common.Conv                      [64, 64, 3, 1]
  8                  -1   1      36992    models.common.Conv                      [64, 64, 3, 1]
  9                  -1   1      36992    models.common.Conv                      [64, 64, 3, 1]
 10    [-1, -3, -5, -6]   1          0    models.common.Concat                    [1]
 11                  -1   1      66048    models.common.Conv                      [256, 256, 1, 1]
 12                  -1   1          0    models.common.MP                        []
 13                  -1   1      33024    models.common.Conv                      [256, 128, 1, 1]
 14                  -3   1      33024    models.common.Conv                      [256, 128, 1, 1]
 15                  -1   1     147712    models.common.Conv                      [128, 128, 3, 2]
 16            [-1, -3]   1          0    models.common.Concat                    [1]
 17                  -1   1      33024    models.common.Conv                      [256, 128, 1, 1]
 18                  -2   1      33024    models.common.Conv                      [256, 128, 1, 1]
 19                  -1   1     147712    models.common.Conv                      [128, 128, 3, 1]
 20                  -1   1     147712    models.common.Conv                      [128, 128, 3, 1]
 21                  -1   1     147712    models.common.Conv                      [128, 128, 3, 1]
 22                  -1   1     147712    models.common.Conv                      [128, 128, 3, 1]
 23    [-1, -3, -5, -6]   1          0    models.common.Concat                    [1]
 24                  -1   1     263168    models.common.Conv                      [512, 512, 1, 1]
 25                  -1   1          0    models.common.MP                        []
 26                  -1   1     131584    models.common.Conv                      [512, 256, 1, 1]
 27                  -3   1     131584    models.common.Conv                      [512, 256, 1, 1]
 28                  -1   1     590336    models.common.Conv                      [256, 256, 3, 2]
 29            [-1, -3]   1          0    models.common.Concat                    [1]
 30                  -1   1     131584    models.common.Conv                      [512, 256, 1, 1]
 31                  -2   1     131584    models.common.Conv                      [512, 256, 1, 1]
 32                  -1   1     590336    models.common.Conv                      [256, 256, 3, 1]
 33                  -1   1     590336    models.common.Conv                      [256, 256, 3, 1]
 34                  -1   1     590336    models.common.Conv                      [256, 256, 3, 1]
 35                  -1   1     590336    models.common.Conv                      [256, 256, 3, 1]
 36    [-1, -3, -5, -6]   1          0    models.common.Concat                    [1]
 37                  -1   1    1050624    models.common.Conv                      [1024, 1024, 1, 1]
 38                  -1   1          0    models.common.MP                        []
 39                  -1   1     525312    models.common.Conv                      [1024, 512, 1, 1]
 40                  -3   1     525312    models.common.Conv                      [1024, 512, 1, 1]
 41                  -1   1    2360320    models.common.Conv                      [512, 512, 3, 2]
 42            [-1, -3]   1          0    models.common.Concat                    [1]
 43                  -1   1     262656    models.common.Conv                      [1024, 256, 1, 1]
 44                  -2   1     262656    models.common.Conv                      [1024, 256, 1, 1]
 45                  -1   1     590336    models.common.Conv                      [256, 256, 3, 1]
 46                  -1   1     590336    models.common.Conv                      [256, 256, 3, 1]
 47                  -1   1     590336    models.common.Conv                      [256, 256, 3, 1]
 48                  -1   1     590336    models.common.Conv                      [256, 256, 3, 1]
 49    [-1, -3, -5, -6]   1          0    models.common.Concat                    [1]
 50                  -1   1    1050624    models.common.Conv                      [1024, 1024, 1, 1]
 51                  -1   1    7609344    models.common.SPPCSPC                   [1024, 512, 1]                     head:
 52                  -1   1     131584    models.common.Conv                      [512, 256, 1, 1]
 53                  -1   1          0    torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']
 54                  37   1     262656    models.common.Conv                      [1024, 256, 1, 1]
 55            [-1, -2]   1          0    models.common.Concat                    [1]
 56                  -1   1     131584    models.common.Conv                      [512, 256, 1, 1]
 57                  -2   1     131584    models.common.Conv                      [512, 256, 1, 1]
 58                  -1   1     295168    models.common.Conv                      [256, 128, 3, 1]
 59                  -1   1     147712    models.common.Conv                      [128, 128, 3, 1]
 60                  -1   1     147712    models.common.Conv                      [128, 128, 3, 1]
 61                  -1   1     147712    models.common.Conv                      [128, 128, 3, 1]
 62 [-1,-2,-3,-4,-5,-6]   1          0    models.common.Concat                    [1]
 63                  -1   1     262656    models.common.Conv                      [1024, 256, 1, 1]
 64                  -1   1      33024    models.common.Conv                      [256, 128, 1, 1]
 65                  -1   1          0    torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']
 66                  24   1      65792    models.common.Conv                      [512, 128, 1, 1]
 67            [-1, -2]   1          0    models.common.Concat                    [1]
 68                  -1   1      33024    models.common.Conv                      [256, 128, 1, 1]
 69                  -2   1      33024    models.common.Conv                      [256, 128, 1, 1]
 70                  -1   1      73856    models.common.Conv                      [128, 64, 3, 1]
 71                  -1   1      36992    models.common.Conv                      [64, 64, 3, 1]
 72                  -1   1      36992    models.common.Conv                      [64, 64, 3, 1]
 73                  -1   1      36992    models.common.Conv                      [64, 64, 3, 1]
 74 [-1,-2,-3,-4,-5,-6]   1          0    models.common.Concat                    [1]
 75                  -1   1      65792    models.common.Conv                      [512, 128, 1, 1]
 76                  -1   1          0    models.common.MP                        []   
 77                  -1   1      16640    models.common.Conv                      [128, 128, 1, 1]
 78                  -3   1      16640    models.common.Conv                      [128, 128, 1, 1]
 79                  -1   1     147712    models.common.Conv                      [128, 128, 3, 2]
 80        [-1, -3, 63]   1          0    models.common.Concat                    [1]
 81                  -1   1     131584    models.common.Conv                      [512, 256, 1, 1]
 82                  -2   1     131584    models.common.Conv                      [512, 256, 1, 1]
 83                  -1   1     295168    models.common.Conv                      [256, 128, 3, 1]
 84                  -1   1     147712    models.common.Conv                      [128, 128, 3, 1]
 85                  -1   1     147712    models.common.Conv                      [128, 128, 3, 1]
 86                  -1   1     147712    models.common.Conv                      [128, 128, 3, 1]
 87 [-1,-2,-3,-4,-5,-6]   1          0    models.common.Concat                    [1]
 88                  -1   1     262656    models.common.Conv                      [1024, 256, 1, 1]
 89                  -1   1          0    models.common.MP                        []
 90                  -1   1      66048    models.common.Conv                      [256, 256, 1, 1]
 91                  -3   1      66048    models.common.Conv                      [256, 256, 1, 1]
 92                  -1   1     590336    models.common.Conv                      [256, 256, 3, 2]
 93        [-1, -3, 51]   1          0    models.common.Concat                    [1]
 94                  -1   1     525312    models.common.Conv                      [1024, 512, 1, 1]
 95                  -2   1     525312    models.common.Conv                      [1024, 512, 1, 1]
 96                  -1   1    1180160    models.common.Conv                      [512, 256, 3, 1]
 97                  -1   1     590336    models.common.Conv                      [256, 256, 3, 1]
 98                  -1   1     590336    models.common.Conv                      [256, 256, 3, 1]
 99                  -1   1     590336    models.common.Conv                      [256, 256, 3, 1]
100 [-1,-2,-3,-4,-5,-6]   1          0    models.common.Concat                    [1]
101                  -1   1    1049600    models.common.Conv                      [2048, 512, 1, 1]
102                  75   1     328704    models.common.RepConv                   [128, 256, 3, 1]
103                  88   1    1312768    models.common.RepConv                   [256, 512, 3, 1]
104                 101   1    5246976    models.common.RepConv                   [512, 1024, 3, 1]
105     [102, 103, 104]   1      44944    models.yolo.IDetect                     [3, [[12, 16, 19, 36, 40, 28], [36, 75, 76, 55, 72, 146], [142, 110, 192, 243, 459, 401]], [256, 512, 1024]]
  

C:\Users\user\AppData\Local\Programs\Python\Python312\Lib\site-packages\torch\functional.py:512: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ..\aten\src\ATen\native\TensorShape.cpp:3588.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
Model Summary: 415 layers, 37207344 parameters, 37207344 gradients, 105.1 GFLOPS

Transferred 552/566 items from ./yolov7/yolov7.pt
Scaled weight_decay = 0.0005
Optimizer groups: 95 .bias, 95 conv.weight, 98 other
train: Scanning 'yolov7\dataset\train\labels.cache' images and labels..
val: Scanning 'yolov7\dataset\test\labels.cache' images and labels... 2

autoanchor: Analyzing anchors... anchors/target = 5.91, Best Possible Recall (BPR) = 0.9994
Image sizes 640 train, 640 test
Using 4 dataloader workers
Logging results to runs\train\run
Starting training for 200 epochs...


convolutional layer (conv) -> [input_channels, output_channels, kernel_size, stride]
concatenation layer (concat) -> [dimension]
Max Pooling layer (MP) -> 
The Spatial Pyramid Pooling (SPP) with Cross Stage Partial connections (CSPC) layer SPPCSPC -> [input_channels, output_channels, number_of_pools]

Conv Layer (models.common.Conv)
Purpose: The convolutional layer (Conv) is a fundamental building block of Convolutional Neural Networks (CNNs). It applies a convolution operation to the input, which allows the network to learn spatial hierarchies of features from the input images.
Arguments: [input_channels, output_channels, kernel_size, stride]
input_channels: Number of input channels (e.g., 3 for RGB images).
output_channels: Number of output channels (number of filters).
kernel_size: Size of the convolution filter (e.g., 3x3).
stride: Stride of the convolution (how much the filter moves at each step).

Concat Layer (models.common.Concat)
Purpose: The concatenation layer (Concat) combines multiple feature maps along a specified dimension. It is often used to merge features from different layers, allowing the network to capture and integrate multi-scale information.
Arguments: [dimension]
dimension: The dimension along which to concatenate the feature maps (e.g., along the channel dimension).
MP Layer (models.common.MP)
Purpose: The Max Pooling layer (MP) reduces the spatial dimensions (width and height) of the input feature maps by taking the maximum value over a sliding window. This operation helps in reducing the computational load and controlling overfitting by providing translation invariance.
Arguments: None, it typically uses a fixed window size (e.g., 2x2) and stride.

SPPCSPC Layer (models.common.SPPCSPC)
Purpose: The Spatial Pyramid Pooling (SPP) with Cross Stage Partial connections (CSPC) layer is a combination layer that enhances the receptive field of the network. SPP allows the network to pool features at different scales, while CSPC helps in gradient flow and feature reuse.
Arguments: [input_channels, output_channels, number_of_pools]
This layer applies multiple pooling operations with different kernel sizes and concatenates their outputs.

Upsample Layer (torch.nn.modules.upsampling.Upsample)
Purpose: The Upsample layer increases the spatial dimensions (width and height) of the input feature maps. It is used in the decoder part of the network, particularly in tasks like object detection and segmentation to restore the original resolution of the input image.
Arguments: [scale_factor, mode]
scale_factor: The factor by which to increase the dimensions.
mode: The interpolation method to use (e.g., 'nearest', 'bilinear').

RepConv Layer (models.common.RepConv)
Purpose: RepVGG Convolutional layer (RepConv) is used for structural re-parameterization, where a multi-branch structure is converted into a simple structure during inference, improving inference speed without sacrificing accuracy.
Arguments: [input_channels, output_channels, kernel_size, stride]
Similar to the standard Conv layer, but optimized for re-parameterization.

IDetect Layer (models.yolo.IDetect)
Purpose: The detection layer (IDetect) is specific to YOLO (You Only Look Once) models and is responsible for producing the final detection results. It processes the feature maps from the preceding layers to predict bounding boxes, objectness scores, and class probabilities.
Arguments: [number_of_classes, anchor_boxes, output_channels]
number_of_classes: The number of object classes to detect.
anchor_boxes: Predefined shapes of the bounding boxes.
output_channels: Number of output channels for each detection head.

The discrepancy between the visible layers (105) and the total layers reported (415) in the model summary can be attributed to several factors. Here's a detailed explanation:

Visible Layers vs. Total Layers
Basic Operations as Layers:

Each layer in the network might represent a high-level operation like Conv, Concat, MP, SPPCSPC, etc., but internally, these operations can consist of multiple sub-operations or primitive operations which are also counted as layers.
Complex Layers:

Complex layers like RepConv or SPPCSPC might encapsulate multiple layers within themselves. For instance, RepConv includes several convolution operations, batch normalizations, and activation functions, each contributing to the total layer count.
Repeated Layers:

Layers that are reused or applied multiple times within complex operations or across different stages of the model can increase the layer count. For example, a Conv layer applied several times within a block will add to the total layer count each time it is used.
Implicit Layers:

There might be implicit layers involved in operations such as activation functions (e.g., ReLU, Sigmoid), normalization layers (e.g., BatchNorm), and other utility layers that are not explicitly listed in the high-level architecture description.
Specific Layers Explained
Here's a brief explanation of each layer type mentioned:

Conv (Convolutional Layer):

Applies convolution operations, which involve sliding filters over input data to produce feature maps.
Each Conv layer typically includes a convolution operation, followed by a non-linear activation function and sometimes batch normalization.
Concat (Concatenation Layer):

Concatenates outputs from multiple layers along a specified dimension, usually the channel dimension.
This operation helps in combining features from different layers, enhancing feature representation.
MP (Max Pooling Layer):

Applies max pooling operations to reduce the spatial dimensions of the input while retaining the most important features.
Commonly used to downsample feature maps and reduce computational load.
SPPCSPC (Spatial Pyramid Pooling with CSP Connection):

Combines spatial pyramid pooling, which applies pooling operations at multiple scales, with CSP (Cross Stage Partial) connections to enhance feature extraction and maintain a rich feature set.
This layer is particularly useful for object detection models, capturing features at multiple scales.
torch.nn.modules.upsampling.Upsample (Upsampling Layer):

Performs upsampling, increasing the spatial dimensions of the input, often using techniques like nearest-neighbor interpolation.
Useful in decoder stages of models, especially in segmentation tasks.
RepConv (Reparameterizable Convolutional Layer):

Combines multiple convolutional operations into a single layer for inference, optimizing the model for faster execution without changing the architecture during training.
Typically involves multiple convolutions that are reparameterized into a single equivalent convolution at inference time.
IDetect (Detection Layer):

Specific to YOLO models, it outputs the final detections including class probabilities, bounding box coordinates, and objectness scores.
Configured with anchor boxes and performs the final prediction step.
Detailed Layer Example
Let's take an example to illustrate how multiple internal operations contribute to the total layer count:

RepConv:

Might consist of three convolutions: one main convolution and two side convolutions for reparameterization.
Each convolution operation includes the convolution itself, batch normalization, and an activation function (e.g., ReLU).
Therefore, a single RepConv layer can internally consist of multiple sub-layers.
Concat:

While a Concat layer might appear as a single operation, it involves internal memory operations to concatenate tensors along a specified dimension.
SPPCSPC:

Involves multiple pooling operations at different scales, each contributing to the total layer count.
Also includes convolutions and concatenations within its implementation.
Conclusion
